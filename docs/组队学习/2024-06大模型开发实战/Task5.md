# 如何评估 LLM 应用

## 验证评估的一般思路

![image-20240627153913436](img/Task5//image-20240627153913436.png)

# 大模型评估方法

## **评估的一般思路**

- 开发基于LLM的应用时，重点在于快速迭代和验证。从小样本开始调整Prompt，逐步处理棘手案例，并将这些案例加入开发集进行测试。

## **评估方法**

### 人工评估

#### 量化评估

可以根据个人风格和业务实际情况制定量化的量纲

#### 多维评估

在本项目中，我们可以设计如下几个维度的评估：

-  知识查找正确性。该维度需要查看系统从向量数据库查找相关知识片段的中间结果，评估系统查找到的知识片段是否能够对问题做出回答。该维度为0-1评估，即打分为0指查找到的知识片段不能做出回答，打分为1指查找到的知识片段可以做出回答。

- 回答一致性。该维度评估系统的回答是否针对用户问题展开，是否有偏题、错误理解题意的情况，该维度量纲同样设计为0~1，0为完全偏题，1为完全切题，中间结果可以任取。

- 回答幻觉比例。该维度需要综合系统回答与查找到的知识片段，评估系统的回答是否出现幻觉，幻觉比例有多高。该维度同样设计为0~1,0为全部是模型幻觉，1为没有任何幻觉。

- 回答正确性。该维度评估系统回答是否正确，是否充分解答了用户问题，是系统最核心的评估指标之一。该维度可以在0~1之间任意打分。

- 逻辑性。该维度评估系统回答是否逻辑连贯，是否出现前后冲突、逻辑混乱的情况。该维度为0-1评估。

- 通顺性。该维度评估系统回答是否通顺、合乎语法，可以在0~1之间任意打分。

- 智能性。该维度评估系统回答是否拟人化、智能化，是否能充分让用户混淆人工回答与智能回答。该维度可以在0~1之间任意打分。

### **自动评估**

随着系统优化和验证集的扩大，引入自动评估方法，如构造客观题、计算答案相似度等。

- **构造客观题**：
  - 将部分主观题转化为客观题，通过对比模型答案和标准答案来评估。

- **计算答案相似度**：
  - 使用BLEU等指标计算模型生成答案与标准答案的相似度，从而评估答案质量。

- **使用大模型进行评估**：
  - 利用大模型自身的评估能力，构造Prompt Engineering让大模型对其他模型的回答进行评分。

- **混合评估**：
  - 结合人工评估、自动评估和大模型评估的优势，对不同评估维度采用最适合的方法。

- **评估维度**：
  - 设计了多个评估维度，包括知识查找正确性、回答一致性、回答幻觉比例、回答正确性、逻辑性、通顺性和智能性。

# 评估并优化生成部分

RAG 全称为检索增强生成，因此，其有两个核心部分：检索部分和生成部分。

## 提升直观回答质量

寻找 Bad Case 的思路有很多，最直观也最简单的就是评估直观回答的质量，结合原有资料内容，判断在什么方面有所不足。

## 标明知识来源，提高可信度

要求模型在生成回答时注明知识来源，避免模型杜撰并不存在于给定资料的知识

## 构造思维链

将 Prompt 构造成一系列步骤来尽量减少其能力限制，例如，我们可以构造一个两步的思维链，要求模型在第二步做出反思

## 增加一个指令解析

在我们的检索 LLM 之前，增加一层 LLM 来实现指令的解析，将用户问题的格式要求和问题内容拆分开来。

# 评估并优化检索部分

检索部分的检索精确率和召回率其实更大程度影响了应用的整体性能

## 评估检索效果

一定要保证我们的每一个验证 query 的正确答案都确实存在于知识库中；

如果正确答案本就不存在，那我们应该将 Bad Case 归因到知识库构建部分

## 优化检索的思路

###  知识片段被割裂导致答案丢失

优化文本切割方式：

- 对于一些格式统一、组织清晰的知识文档，我们可以针对性构建更合适的分割规则；

- 对于格式混乱、无法形成统一的分割规则的文档，

### query 提问需要长上下文概括回答

通过使用 LLM 来对长文档进行概括总结，或者预设提问让 LLM 做出回答，从而将此类问题的可能答案预先填入知识库作为单独的 chunk，来一定程度解决该问题。

### 关键词误导

对于用户输入 query，我们首先通过 LLM 来将用户 query 改写成一种合理的形式，去除次要关键词以及可能出现的错字、漏字的影响。

### 匹配关系不合理

优化向量模型或是构建倒排索引。我们可以选择效果更好的向量模型，或是收集部分数据，在自己的业务上微调一个更符合自己业务的向量模型。

虑构建倒排索引，即针对知识库的每一个知识片段，构建一个能够表征该片段内容但和 query 的相对相关性更准确的索引，在检索时匹配索引和 query 的相关性而不是全文