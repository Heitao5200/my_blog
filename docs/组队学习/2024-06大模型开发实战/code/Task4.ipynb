{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备\n",
    "## 数据集下载\n",
    "\n",
    "我们选用 Datawhale 一些经典开源课程作为示例，具体包括：\n",
    "\n",
    "* [《机器学习公式详解》PDF版本](https://github.com/datawhalechina/pumpkin-book/releases)\n",
    "* [《面向开发者的LLM入门教程、第一部分Prompt Engineering》md版本](https://github.com/datawhalechina/llm-cookbook)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-v1.0.0.pdf            LLM-v1.0.0_md.zip         pumpkin_book.pdf\n",
      "LLM-v1.0.0_latex.zip      LLM-v1.0.0_md_dollar.zip\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本数据解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "import pandas as pd\n",
    "\n",
    "# 创建一个 PyMuPDFLoader Class 实例，输入为待加载的 pdf 文档路径\n",
    "loader = PyMuPDFLoader(\"../data/pumpkin_book.pdf\")\n",
    "\n",
    "# 调用 PyMuPDFLoader Class 的函数 load 对 pdf 文件进行加载\n",
    "pdf_pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../data/pumpkin_book.pdf', 'file_path': '../data/pumpkin_book.pdf', 'page': 1, 'total_pages': 196, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20200315)', 'creationDate': \"D:20231117152045-00'00'\", 'modDate': '', 'trapped': ''}\n",
      "------\n",
      "查看该文档的内容:\n",
      "前言\n",
      "“周志华老师的《机器学习》\n",
      "（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”\n",
      "，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。\n",
      "”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”\n",
      "。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”\n",
      "。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；\n",
      "• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；\n",
      "• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；\n",
      "• 若南瓜书里没有你想要查阅的公式，\n",
      "或者你发现南瓜书哪个地方有错误，\n",
      "请毫不犹豫地去我们GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）\n",
      "；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\n",
      "最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、\n",
      "feijuan、\n",
      "Ggmatch、\n",
      "Heitao5200、\n",
      "huaqing89、\n",
      "LongJH、\n",
      "LilRachel、\n",
      "LeoLRH、\n",
      "Nono17、\n",
      "spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”\n",
      "，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_page = pdf_pages[1]\n",
    "print(f\"每一个元素的类型：{type(pdf_page)}.\", \n",
    "    f\"该文档的描述性数据：{pdf_page.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{pdf_page.page_content}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用[pdfdeal](https://github.com/Menghuan1918/pdfdeal?tab=readme-ov-file)库进行pdf文件处理(待优化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pdfdeal.doc2x import Doc2X\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# find_dotenv()\n",
    "# load_dotenv()\n",
    "# import os \n",
    "# Client = Doc2X()\n",
    "# file_type = 'pdf'\n",
    "# path = '../data/'\n",
    "# def gen_folder_list(path,file_type):\n",
    "\n",
    "#     for root, dirs, files in os.walk(path):\n",
    "#         # print(root,dirs,files)\n",
    "#         pdf_list = []\n",
    "#         for file in files:\n",
    "#             if file.endswith(f'.{file_type}'):\n",
    "#                 # print(os.path.join(root,file))\n",
    "#                 pdf_list.append(os.path.join(root,file))\n",
    "#     return pdf_list\n",
    "# filelist = gen_folder_list(path,file_type)\n",
    "# # This is a built-in function for generating the folder under the path of all the pdf, you can give any list of the form of the path of the pdf\n",
    "# Client.pdfdeal(filelist)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='前言\\n“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\\n者通过西瓜书对机器学习有所了解,所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\\n导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\\n具体的推导细节。”\\n读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\\n老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\\n中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以......本南瓜书只能算是我\\n等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\\n下学生”。\\n使用说明\\n南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\\n为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；对于初学机器学习的小白，西瓜书第1章和第2章的公式强烈不建议深究，简单过一下即可，等你学得\\n有点飘的时候再回来啃都来得及；每个公式的解析和推导我们都力(zhi)争(neng)以本科数学基础的视角进行讲解，所以超纲的数学知识\\n我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；若南瓜书里没有你想要查阅的公式，\\n或者你发现南瓜书哪个地方有错误，\\n请毫不犹豫地去我们GitHub的\\nIssues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\\n提交你希望补充的公式编号或者勘误信息，我们通常会在24小时以内给您回复，超过24小时未回复的\\n话可以微信联系我们（微信号：at-Sm1les）；\\n配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\\n在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1版）\\n最新版PDF获取地址：https://github.com/datawhalechina/pumpkin-book/releases\\n编委会\\n主编：Sm1les、archwalker、jbb0523\\n编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\\n封面设计：构思-Sm1les、创作-林王茂盛\\n致谢\\n特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、spareribs、sunchaothu、StevenLzq在最早期的时候对南瓜书所做的贡献。\\n扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\\n版权声明\\n本作品采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可。\\n', metadata={'source': '../data/pumpkin_book.pdf', 'file_path': '../data/pumpkin_book.pdf', 'page': 1, 'total_pages': 196, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20200315)', 'creationDate': \"D:20231117152045-00'00'\", 'modDate': '', 'trapped': ''})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'[^\\u4e00-\\u9fff](\\n)[^\\u4e00-\\u9fff]', re.DOTALL)\n",
    "def clearn_page_content(pdf_page):\n",
    "\n",
    "    pdf_page.page_content = re.sub(pattern, lambda match: match.group(0).replace('\\n', ''), pdf_page.page_content)\n",
    "    pdf_page.page_content = pdf_page.page_content.replace('•', '')\n",
    "    pdf_page.page_content = pdf_page.page_content.replace(' ', '')\n",
    "    # print(pdf_page.page_content)\n",
    "    return pdf_page\n",
    "clearn_page_content(pdf_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 知识库中单段文本长度\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "# 知识库中相邻文本重合长度\n",
    "OVERLAP_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的文件数量：720\n",
      "切分后的字符数（可以用来大致评估 token 数）：308791\n"
     ]
    }
   ],
   "source": [
    "# 使用递归字符文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=OVERLAP_SIZE\n",
    ")\n",
    "split_docs = text_splitter.split_documents(pdf_pages)\n",
    "print(f\"切分后的文件数量：{len(split_docs)}\")\n",
    "\n",
    "print(f\"切分后的字符数（可以用来大致评估 token 数）：{sum([len(doc.page_content) for doc in split_docs])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_llm import ZhipuAILLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ZhipuAILLM(temperature=0,api_key=os.environ['ZHIPUAI_API_KEY'])\n",
    "llm = ZhipuAILLM(\n",
    "    model = 'glm-4',\n",
    "    max_tokens = 256,\n",
    "    temperature = 0.8,\n",
    "    api_key=os.environ['ZHIPUAI_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('你好')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milvus向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import utility\n",
    "from pymilvus import connections\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = 'rag_db'  # Collection name\n",
    "DIMENSION = 768  # Embeddings size\n",
    "COUNT = 1000  # Number of vectors to insert\n",
    "MILVUS_HOST = 'localhost'\n",
    "MILVUS_PORT = '19530' # Inference Arguments\n",
    "BATCH_SIZE = 128\n",
    "MAX_LENGTH = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document2df(pdf_pages):\n",
    "    # 用于获取元数据 存储到向量数据库进行混合向量查询\n",
    "    df_list = []\n",
    "    for pdf_page in pdf_pages:\n",
    "        pdf_page = clearn_page_content(pdf_page)\n",
    "        pdf_page_dict = pdf_page.dict().get('metadata')\n",
    "        pdf_page_dict.update({'page_content':pdf_page.dict().get('page_content')})\n",
    "        df = pd.json_normalize(pdf_page_dict)\n",
    "        df_list.append(df)\n",
    "    df = pd.concat(df_list, ignore_index=True).reset_index()  \n",
    "    return df\n",
    "df = document2df(pdf_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>file_path</th>\n",
       "      <th>page</th>\n",
       "      <th>total_pages</th>\n",
       "      <th>format</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>subject</th>\n",
       "      <th>keywords</th>\n",
       "      <th>creator</th>\n",
       "      <th>producer</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>modDate</th>\n",
       "      <th>trapped</th>\n",
       "      <th>page_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>PDF 1.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LaTeX with hyperref</td>\n",
       "      <td>xdvipdfmx (20200315)</td>\n",
       "      <td>D:20231117152045-00'00'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\u0001本\u0003:2.0.0\\n发布日期:2023.11\\n南⽠书\\nPUMPKINBOOK\\n谢\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>PDF 1.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LaTeX with hyperref</td>\n",
       "      <td>xdvipdfmx (20200315)</td>\n",
       "      <td>D:20231117152045-00'00'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>前言\\n“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>196</td>\n",
       "      <td>PDF 1.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LaTeX with hyperref</td>\n",
       "      <td>xdvipdfmx (20200315)</td>\n",
       "      <td>D:20231117152045-00'00'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2版》←_←\\n目录\\n第1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>196</td>\n",
       "      <td>PDF 1.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LaTeX with hyperref</td>\n",
       "      <td>xdvipdfmx (20200315)</td>\n",
       "      <td>D:20231117152045-00'00'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2版》←_←3.3.1\\n式...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>../data/pumpkin_book.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>196</td>\n",
       "      <td>PDF 1.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LaTeX with hyperref</td>\n",
       "      <td>xdvipdfmx (20200315)</td>\n",
       "      <td>D:20231117152045-00'00'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2版》←_←5.5\\n其他常...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    source                 file_path  page  \\\n",
       "0      0  ../data/pumpkin_book.pdf  ../data/pumpkin_book.pdf     0   \n",
       "1      1  ../data/pumpkin_book.pdf  ../data/pumpkin_book.pdf     1   \n",
       "2      2  ../data/pumpkin_book.pdf  ../data/pumpkin_book.pdf     2   \n",
       "3      3  ../data/pumpkin_book.pdf  ../data/pumpkin_book.pdf     3   \n",
       "4      4  ../data/pumpkin_book.pdf  ../data/pumpkin_book.pdf     4   \n",
       "\n",
       "   total_pages   format title author subject keywords              creator  \\\n",
       "0          196  PDF 1.5                                LaTeX with hyperref   \n",
       "1          196  PDF 1.5                                LaTeX with hyperref   \n",
       "2          196  PDF 1.5                                LaTeX with hyperref   \n",
       "3          196  PDF 1.5                                LaTeX with hyperref   \n",
       "4          196  PDF 1.5                                LaTeX with hyperref   \n",
       "\n",
       "               producer             creationDate modDate trapped  \\\n",
       "0  xdvipdfmx (20200315)  D:20231117152045-00'00'                   \n",
       "1  xdvipdfmx (20200315)  D:20231117152045-00'00'                   \n",
       "2  xdvipdfmx (20200315)  D:20231117152045-00'00'                   \n",
       "3  xdvipdfmx (20200315)  D:20231117152045-00'00'                   \n",
       "4  xdvipdfmx (20200315)  D:20231117152045-00'00'                   \n",
       "\n",
       "                                        page_content  \n",
       "0  \u0001本\u0003:2.0.0\\n发布日期:2023.11\\n南⽠书\\nPUMPKINBOOK\\n谢\\t...  \n",
       "1  前言\\n“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽...  \n",
       "2  →_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2版》←_←\\n目录\\n第1...  \n",
       "3  →_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2版》←_←3.3.1\\n式...  \n",
       "4  →_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2版》←_←5.5\\n其他常...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_collection(COLLECTION_NAME):\n",
    "    if utility.has_collection(COLLECTION_NAME):\n",
    "        utility.drop_collection(COLLECTION_NAME)\n",
    "delete_collection(COLLECTION_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_collection(collection_name):\n",
    " \n",
    "    # 主键\n",
    "    field_id = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True)\n",
    "    # 向量检索的field\n",
    "    field_title = FieldSchema(name='page', dtype=DataType.INT64,  description ='page', max_length=MAX_LENGTH )\n",
    "    field_origin = FieldSchema(name='page_content', dtype=DataType.VARCHAR, description ='page_content' , max_length=8192 )\n",
    "\n",
    "    field_title_embedding = FieldSchema(name='page_content_embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION,description ='page_content' )\n",
    "    # field_plot_embedding = FieldSchema(name='plot_embedding', dtype=DataType.FLOAT_VECTOR,dim=64,description ='Plot' )\n",
    "    schema = CollectionSchema(fields=[field_id, \n",
    "                                      field_title, \n",
    "                                      field_origin,\n",
    "                              \n",
    "                                      field_title_embedding,\n",
    "                                      # field_plot_embedding\n",
    "                                     ], description=\"page_content_collection\")\n",
    "\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "   \n",
    "\n",
    "    return collection\n",
    "  \n",
    "\n",
    "collection = create_collection(COLLECTION_NAME)\n",
    "### 为集合创建IVF_FLAT索引\n",
    "def create_index_collection(collection):\n",
    "\n",
    "    \n",
    "    index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{'nlist': 1536}\n",
    "    }\n",
    "    collection.create_index(field_name=\"page_content_embedding\", index_params=index_params)\n",
    "    collection.load()\n",
    "create_index_collection(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer = SentenceTransformer('/Users/heitao/models/AI-ModelScope/bge-base-zh-v1-5', )\n",
    "# transformer.encode(x)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为collection创建分区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"name\":\"_default\",\"collection_name\":\"rag_db\",\"description\":\"\"}, {\"name\":\"partition_test\",\"collection_name\":\"rag_db\",\"description\":\"\"}]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def create_partition(collection,partition_name):\n",
    "    \"\"\"\n",
    "    为collection创建分区\n",
    "    :param collection:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    partition = collection.create_partition(partition_name)\n",
    "    print(collection.partitions)\n",
    "    print(collection.has_partition(partition_name))\n",
    "    \n",
    "create_partition(collection,partition_name = 'partition_test')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 插入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_collection(df ):\n",
    "    \n",
    "    field_page = df['page'].to_list()\n",
    "    field_page_content = df['page_content'].to_list()\n",
    "\n",
    "    sentences = df['page_content'].to_list()\n",
    "    embeddings = transformer.encode(sentences)\n",
    "    ins = [ field_page,field_page_content,embeddings]\n",
    "    collection.insert(ins)\n",
    "    collection.flush()\n",
    "insert_data_collection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_query(search_terms):\n",
    "    embeds = transformer.encode(search_terms) \n",
    "    return [x for x in embeds]\n",
    "# Search for titles that closest match these phrases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(search_terms, top_k=3):\n",
    "    \n",
    "    search_data = embedding_query(search_terms)\n",
    "    res = collection.search(\n",
    "        data=search_data,  # Embeded search value\n",
    "        anns_field=\"page_content_embedding\",  # Search across embeddings\n",
    "        param={\n",
    "                # \"nprobe\": 128,\n",
    "                # \"metric_type\": \"L2\",\n",
    "                # \"offset\": 10,\n",
    "                # \"limit\": 10,\n",
    "                        },\n",
    "        limit = top_k,  # Limit to top_k results per search\n",
    "        output_fields=['page_content']  # Include title field in result\n",
    "    )\n",
    "    result = []\n",
    "    for hits_i, hits in enumerate(res):\n",
    "        print('Title:', search_terms[hits_i])\n",
    "        # print('Search Time:', end-start)\n",
    "        # print('Results:')\n",
    "        for hit in hits:\n",
    "            # print( hit.entity.get('page_content'), '----', hit.distance)\n",
    "            result.append(hit.entity.get('page_content'))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己定义一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 孙悟空的师傅是谁\n",
      "我不知道孙悟空的师傅是谁，因为上下文中没有提到相关信息。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "def rag(question):\n",
    "    search_terms = [question]\n",
    "    result = get_result(search_terms)\n",
    "    template = \"\"\"使用以下上下文来回答最后的问题。如果所给的上下文中没有提到相关的答案，就说你不知道，不要试图编造答\n",
    "    案。最多使用三句话。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "    上下文内容：{}\n",
    "    问题: {}\n",
    "    \"\"\".format('\\n'.join(result),search_terms[0])\n",
    "\n",
    "    answer = llm(template)\n",
    "    print(answer)\n",
    "    return answer\n",
    "question = '孙悟空的师傅是谁'\n",
    "answer = rag(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores.milvus import Milvus\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='/Users/heitao/models/AI-ModelScope/bge-base-zh-v1-5')\n",
    "\n",
    "loader = PyPDFLoader(\"../data/pumpkin_book.pdf\")\n",
    "data = loader.load()\n",
    "\n",
    "# Split docs\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "# Insert the documents in Milvus Vector Store\n",
    "vector_db = Milvus.from_documents(\n",
    "    docs,\n",
    "    embedding_model,\n",
    "    collection_name='test',\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT},\n",
    "    )\n",
    "\n",
    "\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "案。最多使用三句话。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\",\"question\"],\n",
    "                                 template=template)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vector_db.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n",
    "question_1 = \"什么是南瓜书？\"\n",
    "question_2 = \"王阳明是谁？\"\n",
    "\n",
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 部署知识库助手 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 11:41:49.968 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/llm/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "st.title('🦜🔗 动手学大模型应用开发')\n",
    "zhipuai_api_key = st.sidebar.text_input('ZhiPu API Key', type='password')\n",
    "def generate_response(input_text):\n",
    "    llm = ChatOpenAI(temperature=0.7, openai_api_key=zhipuai_api_key)\n",
    "    st.info(llm(input_text))\n",
    "with st.form('my_form'):\n",
    "    text = st.text_area('Enter text:', 'What are the three key pieces of advice for learning how to code?')\n",
    "    submitted = st.form_submit_button('Submit')\n",
    "    if not zhipuai_api_key.startswith('sk-'):\n",
    "        st.warning('Please enter your OpenAI API key!', icon='⚠')\n",
    "    if submitted and zhipuai_api_key.startswith('sk-'):\n",
    "        generate_response(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "import sys\n",
    "sys.path.append(\"../C3 搭建知识库\") # 将父目录放入系统路径中\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "from zhipuai_llm import ZhipuAILLM\n",
    "from langchain.vectorstores.milvus import Milvus\n",
    "\n",
    "#export OPENAI_API_KEY=\n",
    "#os.environ[\"OPENAI_API_BASE\"] = 'https://api.chatgptid.net/v1'\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "embedding = HuggingFaceEmbeddings(model_name='/Users/heitao/models/AI-ModelScope/bge-base-zh-v1-5')\n",
    "loader = PyPDFLoader(\"../data/pumpkin_book.pdf\")\n",
    "data = loader.load()\n",
    "# llm = ZhipuAILLM(temperature=0,api_key=os.environ['ZHIPUAI_API_KEY'])\n",
    "llm = ZhipuAILLM(\n",
    "    model = 'glm-4',\n",
    "    max_tokens = 256,\n",
    "    temperature = 0.8,\n",
    "    api_key=os.environ['ZHIPUAI_API_KEY']\n",
    ")\n",
    "# Split docs\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(data)\n",
    "def generate_response(input_text, openai_api_key,llm = llm):\n",
    "    # llm = ChatOpenAI(temperature=0.7, openai_api_key=openai_api_key)\n",
    "    output = llm.invoke(input_text)\n",
    "    output_parser = StrOutputParser()\n",
    "    output = output_parser.invoke(output)\n",
    "    #st.info(output)\n",
    "    return output\n",
    "\n",
    "def get_vectordb(docs = docs,embedding = embedding):\n",
    "    MILVUS_HOST = 'localhost'\n",
    "    MILVUS_PORT = '19530' # Inference Arguments\n",
    "    # 定义 Embeddings\n",
    "    # embedding = ZhipuAIEmbeddings()\n",
    "    \n",
    "    # 向量数据库持久化路径\n",
    "\n",
    "    # persist_directory = './chroma'\n",
    "    # 加载数据库\n",
    "    # vectordb = Chroma(\n",
    "    #     persist_directory=persist_directory,  # 允许我们将persist_directory目录保存到磁盘上\n",
    "    #     embedding_function=embedding\n",
    "    # )\n",
    "    vectordb = Milvus.from_documents(\n",
    "    docs,\n",
    "    embedding,\n",
    "    collection_name='test',\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT},\n",
    "    )\n",
    "    return vectordb\n",
    "\n",
    "#带有历史记录的问答链\n",
    "def get_chat_qa_chain(question:str,openai_api_key:str,llm = llm):\n",
    "    vectordb = get_vectordb()\n",
    "    # llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature = 0,openai_api_key = openai_api_key)\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "        return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    "    )\n",
    "    retriever=vectordb.as_retriever()\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm,\n",
    "        retriever=retriever,\n",
    "        memory=memory\n",
    "    )\n",
    "    result = qa({\"question\": question})\n",
    "    return result['answer']\n",
    "\n",
    "#不带历史记录的问答链\n",
    "def get_qa_chain(question:str,openai_api_key:str,llm = llm):\n",
    "    vectordb = get_vectordb()\n",
    "    # llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature = 0,openai_api_key = openai_api_key)\n",
    "    template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "        案。最多使用三句话。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "        {context}\n",
    "        问题: {question}\n",
    "        \"\"\"\n",
    "    QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\",\"question\"],\n",
    "                                 template=template)\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n",
    "    result = qa_chain({\"query\": question})\n",
    "    return result[\"result\"]\n",
    "\n",
    "\n",
    "# Streamlit 应用程序界面\n",
    "def main():\n",
    "    st.title('🦜🔗 动手学大模型应用开发')\n",
    "    openai_api_key = st.sidebar.text_input('暗号', type='password')\n",
    "\n",
    "    # 添加一个选择按钮来选择不同的模型\n",
    "    #selected_method = st.sidebar.selectbox(\"选择模式\", [\"qa_chain\", \"chat_qa_chain\", \"None\"])\n",
    "    selected_method = st.radio(\n",
    "        \"你想选择哪种模式进行对话？\",\n",
    "        [\"None\", \"qa_chain\", \"chat_qa_chain\"],\n",
    "        captions = [\"不使用检索问答的普通模式\", \"不带历史记录的检索问答模式\", \"带历史记录的检索问答模式\"])\n",
    "\n",
    "    # 用于跟踪对话历史\n",
    "    if 'messages' not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "    messages = st.container(height=300)\n",
    "    if prompt := st.chat_input(\"Say something\"):\n",
    "        # 将用户输入添加到对话历史中\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"text\": prompt})\n",
    "\n",
    "        if selected_method == \"None\":\n",
    "            # 调用 respond 函数获取回答\n",
    "            answer = generate_response(prompt, openai_api_key)\n",
    "        elif selected_method == \"qa_chain\":\n",
    "            answer = get_qa_chain(prompt,openai_api_key)\n",
    "        elif selected_method == \"chat_qa_chain\":\n",
    "            answer = get_chat_qa_chain(prompt,openai_api_key)\n",
    "\n",
    "        # 检查回答是否为 None\n",
    "        if answer is not None:\n",
    "            # 将LLM的回答添加到对话历史中\n",
    "            st.session_state.messages.append({\"role\": \"assistant\", \"text\": answer})\n",
    "\n",
    "        # 显示整个对话历史\n",
    "        for message in st.session_state.messages:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                messages.chat_message(\"user\").write(message[\"text\"])\n",
    "            elif message[\"role\"] == \"assistant\":\n",
    "                messages.chat_message(\"assistant\").write(message[\"text\"])   \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化点\n",
    "1. Chroma本地向量库改为 Milvus 线上向量库\n",
    "2. 元数据一同存储到Milvus，支持混合检索\n",
    "3. 线上的 embedding 模型改为本地的embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
