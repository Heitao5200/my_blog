## 查询重写的重要性

- 在RAG中，用户原始查询可能存在措辞不准确或缺乏语义信息的问题，导致LLM无法给出正确或满意的回答。

- 查询重写技术通过将用户查询的语义空间与文档的语义空间对齐，提高检索的准确性和生成答案的相关性。

  ![Image](img/Task28探索RAG query重写/640-20240405180700322)

## 查询重写技术概览
- **Hypothetical Document Embeddings (HyDE)**: 通过假设文档来对齐查询和文档的语义空间。
- **Rewrite-Retrieve-Read**: 采用不同于传统检索和阅读顺序的框架，专注于查询重写。
- **Step-Back Prompting**: 允许LLM基于高级概念进行抽象推理和检索。
- **Query2Doc**: 使用LLM生成伪文档，并将其与原始查询合并构建新查询。
- **ITER-RETGEN**: 结合生成结果与先前查询，通过迭代过程提高检索和生成的协同效果。

## HyDE方法详解

HyDE的目标是生成假设文档，以便最终查询向量v与向量空间中的实际文档尽可能紧密地对齐

- HyDE方法通过以下步骤实现查询重写：
  - 使用LLM基于查询生成假设文档
    - 这些生成的文件可能不是事实，也可能包含错误，但它们应该于相关文件相似
    - 目的是通过LLM解释用户的查询
  
  - 将假设文档输入编码器映射到密集向量。
  
  - 计算假设文档向量的平均值，包括原始查询。
  
  - 使用向量从文档库中检索答案。

## 重写-检索-读取框架



- 该框架建议首先使用LLM重写查询，然后进行检索和生成答案，而不是直接从原始查询中检索内容。

  ![Image](img/Task28探索RAG query重写/640-20240405202827523)

## Step-Back提示技术

- Step-Back提示技术通过提出更广泛的问题帮助模型有效地回答特定查询，从而避免直接推理时的错误。

- STEP-BACK PROMPING包括两个基本步骤：

  - **抽象**：最初，我们**提示LLM提出一个关于高级概念或原理的广泛问题**，而不是直接响应查询。然后，我们检索关于所述概念或原理的相关事实。

  - **推理**：LLM可以**根据这些关于高级概念或原理的事实推导出原始问题的答案**。我们称之为抽象推理。

- 示例：

  ```
  “Estela Leopold在特定时间上了哪所学校”，我们可以问“Estella Leopoold的教育史”
  ```

  这个更广泛的主题涵盖了原始问题，可以提供所有必要的信息来推断“Estela Leopold在特定时间上过哪所学校”。需要注意的是，这些更广泛的问题通常比原始的特定问题更容易回答。

  

## Query2Doc方法

- Query2Doc通过生成伪文档并与原始查询组合，创建新的查询，以改善查询的表示。

- 每次迭代t中，我们首先使用上一次迭代的生成yt-1，将其与q组合，并检索前k个段落。接下来，我们提示LLM生成输出yt，该输出yt将检索到的段落（表示为Dyt-1||q）和q合并到提示中。

  

## ITER-RETGEN方法
- ITER-RETGEN通过迭代过程结合生成内容指导检索，实现检索增强的生成和生成增强的检索。

  ![Image](img/Task28探索RAG query重写/640-20240405203815559)

## 结论
- 查询重写技术在RAG中扮演着关键角色，可以显著提高检索的准确性和生成答案的质量。
- 不同的查询重写方法适用于不同的场景，需要根据实际情况进行选择和组合。
- 尽管查询重写技术有其优势，但在实际应用中仍需考虑性能权衡。

