{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed21052f-6ead-419d-8ea9-11ba66632f9e",
   "metadata": {},
   "source": [
    "# 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8f061-5d26-4295-b1cd-3ed1881d321b",
   "metadata": {},
   "source": [
    "## 原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35102f2d-0fc7-45ee-a4d2-b9ab003bb5f6",
   "metadata": {},
   "source": [
    "建模时采用线性代数表示法会比较方便。当我们的输入 包含 $d$ 个特征时，我们将预测结果 $\\hat{y}$ （通常使用“尖角\"符号表示 $y$ 的估计值）表示为：\n",
    "$$\n",
    "\\hat{y}=w_1 x_1+\\ldots+w_d x_d+b\n",
    "$$\n",
    "将所有特征放到向量 $\\mathbf{x} \\in \\mathbb{R}^d$ 中, 并将所有权重放到向量 $\\mathbf{w} \\in \\mathbb{R}^d$ 中, 我们可以用点积形式来简洁地表达模 型:\n",
    "$$\n",
    "\\hat{y}=\\mathbf{w}^{\\top} \\mathbf{x}+b\n",
    "$$\n",
    "向量 $\\mathbf{x}$ 对应于单个数据样本的特征。用符号表示的矩阵 $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ 可以很方便地引用我们整个 数据集的 $n$ 个样本。其中, $\\mathbf{X}$ 的每一行是一个样本, 每一列是一种特征。\n",
    "对于特征集合 $\\mathbf{X}$, 预测值 $\\hat{\\mathbf{y}} \\in \\mathbb{R}^n$ 可以通过矩阵-向量乘法表示为:\n",
    "$$\n",
    "\\hat{\\mathbf{y}}=\\mathbf{X} \\mathbf{w}+b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aadca9-5479-4741-ba9d-f9dee439c779",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d726cb-223f-47e8-b497-74b8cf15ad8a",
   "metadata": {},
   "source": [
    "损失函数 (loss function）能够量化目标的实际值与预测値之间的差距。\n",
    "\n",
    "通常我们会选择非负数作为损失, 且数值越小表示 损失越小, 完美预测时的损失为 0 。 \n",
    "\n",
    "回归问题中最常用的损失函数是平方误差函数。当样本 $i$ 的预测值为 $\\hat{y}^{(i)}$ , 其相应的真实标签为 $y^{(i)}$ 时, 平方误差可以定义为以下公式:\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b)=\\frac{1}{2}\\left(\\hat{y}^{(i)}-y^{(i)}\\right)^2 .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca9d5f4-a8f8-4a4f-8a9d-329b7e78616c",
   "metadata": {},
   "source": [
    "由于平方误差函数中的二次方项, 估计值 $\\hat{y}^{(i)}$ 和观测值 $y^{(i)}$ 之间较大的差异将导致更大的损失。为了度量模型 在整个数据集上的质量, 我们需计算在训练集 $n$ 个样本上的损失均值（也等价于求和）。\n",
    "$$\n",
    "L(\\mathbf{w}, b)=\\frac{1}{n} \\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b)=\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}+b-y^{(i)}\\right)^2 .\n",
    "$$\n",
    "在训练模型时, 我们希望寻找一组参数 $\\left(\\mathbf{w}^*, b^*\\right)$, 这组参数能最小化在所有训练样本上的总损失。如下 式:\n",
    "$$\n",
    "\\mathbf{w}^*, b^*=\\underset{\\mathbf{w}, b}{\\operatorname{argmin}} L(\\mathbf{w}, b) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac9b1c-cc73-45c2-9b5d-8cef46b50448",
   "metadata": {},
   "source": [
    "## 解析解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940db9e-fb45-4ed4-9463-27b66cb75024",
   "metadata": {},
   "source": [
    "$$\\mathbf{w}^*=\\left(\\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\top} \\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357467e1-c3d5-41d9-babd-a54b7f3749b7",
   "metadata": {},
   "source": [
    "## 随机梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb156c81-f7c1-47c9-8541-299f55023f23",
   "metadata": {},
   "source": [
    "我们用下面的数学公式来表示这一更新过程（ $\\partial$ 表示偏导数）：\n",
    "$$\n",
    "(\\mathbf{w}, b) \\leftarrow(\\mathbf{w}, b)-\\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w}, b)} l^{(i)}(\\mathbf{w}, b)\n",
    "$$\n",
    "\n",
    "(1) 初始化模型参数的值, 如随机初始化; \n",
    "\n",
    "(2) 从数据集中随机抽取小批 量样本且在负梯度的方向上更新参数, 并不断迭代这一步骤。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\mathbf{w} \\leftarrow \\mathbf{w}-\\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{\\mathbf{w}} l^{(i)}(\\mathbf{w}, b)=\\mathbf{w}-\\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\mathbf{x}^{(i)}\\left(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}+b-y^{(i)}\\right), \\\\\n",
    "& b \\leftarrow b-\\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_b l^{(i)}(\\mathbf{w}, b)=b-\\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}}\\left(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}+b-y^{(i)}\\right) .\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485bd5f-7ecd-4b3f-b4a3-b9487460f148",
   "metadata": {},
   "source": [
    "## 正态分布与平方损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad95bd9-c9a1-4cd2-9e05-f7f19dcb27cf",
   "metadata": {},
   "source": [
    "正态分布 (normal distribution) ，也称为高斯分布 (Gaussian distribution）, 最早由德国数学家高斯 (Gauss) 应用于天文学研究。简单的说, 若随机变量 $x$ 具有均值 $\\mu$ 和方差 $\\sigma^2($ 标准差 $\\sigma)$  其 正 态 分 布 概 率 密 度 函 数 如 下: \n",
    "$$\n",
    "p(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left(-\\frac{1}{2 \\sigma^2}(x-\\mu)^2\\right) \\text {. }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58231f6-d54a-42e2-90f5-227c2d981577",
   "metadata": {},
   "source": [
    "# 线性回归的从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225bca9e-07bb-411b-90b0-987740d4fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84276f36-dbf7-4378-97c6-21c44796811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc043fc-f2e5-4ba4-ac60-89c274490cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([ 0.4210, -0.0838]) \n",
      "label: tensor([5.3413])\n"
     ]
    }
   ],
   "source": [
    "print('features:', features[0],'\\nlabel:', labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e6e035-e93f-44c6-ae93-7c1929b006c2",
   "metadata": {},
   "source": [
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35c269cf-3ac8-43e5-aea7-4ea1e629f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7963, -1.3122],\n",
      "        [-0.3924, -1.3052],\n",
      "        [-2.3347, -2.7803],\n",
      "        [ 0.3914,  0.6717],\n",
      "        [-0.8716, -0.8575],\n",
      "        [ 0.2685, -1.3634],\n",
      "        [-2.0699,  0.6321],\n",
      "        [ 0.3147,  2.7199],\n",
      "        [-3.4801,  0.2269],\n",
      "        [ 0.5900,  0.3157]]) \n",
      " tensor([[ 7.0594],\n",
      "        [ 7.8615],\n",
      "        [ 8.9873],\n",
      "        [ 2.6964],\n",
      "        [ 5.3815],\n",
      "        [ 9.3693],\n",
      "        [-2.1011],\n",
      "        [-4.4139],\n",
      "        [-3.5128],\n",
      "        [ 4.3123]])\n"
     ]
    }
   ],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "        \n",
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26781b-659d-46e0-8756-e904243a2933",
   "metadata": {},
   "source": [
    "## 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efaf43b2-875c-4cd9-b977-d6a0defdf99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e31b88-8e06-4ab7-a885-148ebf6b308d",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75da78c5-0cfb-467e-a229-986d95f6867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b): \n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c63482-454e-43e7-b6b2-1019b76f3be5",
   "metadata": {},
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e199347-ea30-44e4-ab68-4ea2b9875332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y): \n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378dc52a-7b49-4c06-a32a-61e20d495c76",
   "metadata": {},
   "source": [
    "## 定义优化算法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90151972-5a08-41f2-87d3-6b358ee7b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  \n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7a4f0-be47-4ffd-953c-1e498eaa7292",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93118d8b-fe07-4574-829a-0970b57907c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.035104\n",
      "epoch 2, loss 0.000128\n",
      "epoch 3, loss 0.000050\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36260c3-a755-401e-80a1-bf64031143fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的估计误差: tensor([ 5.8424e-04, -3.6955e-05], grad_fn=<SubBackward0>)\n",
      "b的估计误差: tensor([0.0005], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a88ef-7f6a-4f23-aa0d-3c73d7c45524",
   "metadata": {},
   "source": [
    "# 线性回归的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4631c233-d8ea-403f-8715-04708b2742c9",
   "metadata": {},
   "source": [
    "##  生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "901f3a7f-5498-4232-90c1-750b699253b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "def synthetic_data(w, b, num_examples):\n",
    "    \"\"\"生成y=Xw+b+噪声\n",
    "\n",
    "    Defined in :numref:`sec_linear_scratch`\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, torch.reshape(y, (-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee0a91-8a01-4173-a76a-11c4aa4a945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e145b3-138b-48d0-b9ad-e44b82a7f9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bfbf744-05fe-4e80-bf16-ae7f0c2fef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a8147a-a147-43de-a8fb-ef752fc522a8",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41fc770a-2591-418b-af07-c1d4bc708a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77c0ca-ba6b-4a73-8913-4ba5cea85277",
   "metadata": {},
   "source": [
    "## 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd091a14-15cd-44e4-8883-b15dbdb8f8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3f93b-1ee4-49da-9627-027b6c4aea92",
   "metadata": {},
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda412b4-3cc0-4c53-82c6-da5ef638b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51615c68-3408-4e79-abe0-a1618c60c60e",
   "metadata": {},
   "source": [
    "## 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7128443f-d25c-4ac1-8c31-395f68717675",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab861932-0486-405e-952b-72e0064904eb",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e56fd7cc-7e9c-4e6a-8856-7b1234895c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 23.247873\n",
      "epoch 2, loss 20.348331\n",
      "epoch 3, loss 17.878389\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X) ,y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c64cf11-4c71-4e0c-b9c6-fec0f4f5db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的估计误差： tensor([ 1.3603, -3.2202])\n",
      "b的估计误差： tensor([3.5735])\n"
     ]
    }
   ],
   "source": [
    "w = net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e6ee4-600a-44fc-99e6-4953107a5052",
   "metadata": {},
   "source": [
    "# softmax回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fe5b3-0682-4332-b52d-ee57425c7696",
   "metadata": {},
   "source": [
    "## 分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c1baf3-0328-4fa6-8ed0-f503ef1cdd15",
   "metadata": {},
   "source": [
    "## 网络架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049b82a3-25fd-4111-b4b3-de9eacd4112a",
   "metadata": {},
   "source": [
    "$$\\begin{aligned} & o_1=x_1 w_{11}+x_2 w_{12}+x_3 w_{13}+x_4 w_{14}+b_1 \\\\ & o_2=x_1 w_{21}+x_2 w_{22}+x_3 w_{23}+x_4 w_{24}+b_2 \\\\ & o_3=x_1 w_{31}+x_2 w_{32}+x_3 w_{33}+x_4 w_{34}+b_3\\end{aligned}$$\n",
    "\n",
    "\n",
    "![](https://zh-v2.d2l.ai/_images/softmaxreg.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b12eb1-9186-4c64-b8fa-f7d35948bf43",
   "metadata": {},
   "source": [
    "## softmax运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c1fa7-fe9b-4f22-8334-57c60e6dfb6e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\mathbf{y}}=\\operatorname{softmax}(\\mathbf{o}) \\quad \\text { 其中 } \\quad \\hat{y}_j=\\frac{\\exp \\left(o_j\\right)}{\\sum_k \\exp \\left(o_k\\right)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\underset{j}{\\operatorname{argmax}} \\hat{y}_j=\\underset{j}{\\operatorname{argmax}} o_j .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82ade0-0268-4985-b463-4d62fb284976",
   "metadata": {},
   "source": [
    "#  图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e47672-c0be-4c80-8a7d-8dfa50330e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbafaa62-b1bd-4b5f-ba21-3efecdfbe221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642494e3-3c03-4ab7-b004-bef382e9f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20798510-8fe6-4903-afb7-e983ee5d55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def use_svg_display():\n",
    "    \"\"\"使用svg格式在Jupyter中显示绘图\n",
    "\n",
    "    Defined in :numref:`sec_calculus`\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1691740-30a8-4708-bd8d-54def463423f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
